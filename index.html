
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Xutianming Blog</title>
  <meta name="author" content="Xutianming">

  
  <meta name="description" content="这两天一直在忙着搭Wikipedia Miner的环境，其中用到了Java和Hadoop相关。Java因为以前做过TopCoder，对于环境配置、Ant使用什么的还比较熟悉，也没有遇到什么大的问题。主要就是Hadoop了，虽然以前实习的时候，也多少接触过Hadoop， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://xutianming.github.io">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Xutianming Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Xutianming Blog</a></h1>
  
    <h2>www.cnblogs.com/iteagle</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:xutianming.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/28/hadoop-first-trial/">Hadoop环境搭建小结</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-28T15:37:00+08:00" pubdate data-updated="true">Sep 28<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/09/28/hadoop-first-trial/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>这两天一直在忙着搭Wikipedia Miner的环境，其中用到了Java和Hadoop相关。Java因为以前做过TopCoder，对于环境配置、Ant使用什么的还比较熟悉，也没有遇到什么大的问题。主要就是Hadoop了，虽然以前实习的时候，也多少接触过Hadoop，用过Hive写过一些Hql什么的，但是只是一些皮毛吧。自己搭建Hadoop环境还是头一回，这次要在我的Mac上，搭一个单机器的双节点伪分布式环境。具体的步骤，参考了官方的手册。</p>

<p><a href="http://sourceforge.net/apps/mediawiki/wikipedia-miner/index.php?title=Extraction">Wikipedia Miner搭建手册</a></p>

<p><a href="http://hadoop.apache.org/docs/stable/single_node_setup.html#PseudoDistributed">Apache Hadoop环境搭建手册</a></p>

<p><a href="http://wiki.apache.org/hadoop/Running_Hadoop_On_OS_X_10.5_64-bit_%28Single-Node_Cluster%29">OSX Hadoop环境搭建手册</a></p>

<p>步骤基本上是结合这几个看的，第一次搭建，就没考虑太多安全性，合理性。先搭个能用的环境体验下再说。具体步骤列举如下：</p>

<ol>
<li>安装JDK并配置JAVA_HOME(PATH,CLASSPATH在MAC上好像是不需要配置的)，<a href="http://blog.csdn.net/johnstrive/article/details/7791451">参考</a></li>
<li>开启mac的远程登录功能，也就是教程里的ssh。<a href="http://stackoverflow.com/questions/12369172/how-to-install-sshd-on-mac">参考</a></li>
<li>通过生成dsa秘钥等工作，ssh localhost可以不输入密码。<a href="http://wiki.apache.org/hadoop/Running_Hadoop_On_OS_X_10.5_64-bit_%28Single-Node_Cluster%29">参考</a>中讲ssh那段有。</li>
<li>下载安装Hadoop，然后配置。<a href="http://hadoop.apache.org/docs/stable/single_node_setup.html#PseudoDistributed">参考</a></li>
<li>运行Hadoop。</li>
</ol>


<p>上面列举出了我配置过来所参考的资料，我当然没有一次成功，每一步都有点小波折的，上面的资料都是我使用的，经过验证的方法。</p>

<p>接着我启动Hadoop，上传我的文件。总是抛异常，就像这个<a href="http://stackoverflow.com/questions/10097246/no-data-nodes-are-started">问题</a>里描述的，SO上有很多类似问题，解决方法也都一样，删除dfs里面的，name和data文件，然后重新format。但是我照做了就没成功，我也没有去读那些log，但是运气比较好的，我发现其实我的Hadoop根本就没有启动任何datanode成功。于是根据提示消息，我找到了这个<a href="http://stackoverflow.com/questions/6307244/hadoop-namenode-format-returns-a-java-net-unknownhostexception">问题</a>。最终我通过在hosts文件中，加了别名，解决了这个问题。</p>

<p>看起来很简单的过程，折腾了得有好几个钟头。到现在为止，hadoop基本上没问题了。但是总体的Wikipedia Miner的环境，还没搭建成功，还得解决各种Exception。等可以顺利使用Wikipedia Miner之后，我还要好好研究下，Wikipedia Miner的hadoop job部分是怎么写的。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/24/summary-of-wikivis-project-2/">知识可视化项目第一阶段总结2</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-24T21:15:00+08:00" pubdate data-updated="true">Sep 24<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/09/24/summary-of-wikivis-project-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>今天和乐乐讨论了发表了Wikipedia Miner思路的论文，感觉颇深，故在此记录一下。</p>

<p>今天其实并没有讨论太多论文的内容，主要是基于项目第一阶段的反思，所以感觉还是很有意义的。这样的话，可以一步一步的提高我们解决问题的能力。关于面对一个要解决的课题的时候，我们从什么角度去思考它的解决方案，以及在目前的解决方案遇到了问题，走入了死胡同，如何调整路线，以最终找到那条正确的道路。</p>

<p>第一个问题是关于思考问题的角度。很明显，在第一阶段的项目进展中，我们并不成功，没有找到一种泛化能力非常好的算法，来对维基百科的数据进行有效的挖掘。在今天读了论文之后，发现论文作者和我们对于问题的思考思路是完全不同的。具体来讲，论文的课题是要解决“给哪些词加链接，有助于读者理解当前的文章”，而我们的目的是“有哪些关键字，可以很好的代表这篇文章，我们要给出这些关键字对应的维基百科链接”（这里仅指我们项目中的关键词打分步骤）。从这个角度看，我们要解决的问题其实是一致的，但是我们分别采用了什么样的思路来思考问题的呢？首先讲论文中的思路，维基百科中现有的有链接的文章是标注好的语料，那么满足什么条件的词是重要的关键字，需要加链接呢？我可以利用机器学习的方法来训练一个模型。首先根据经验选择一些特征，再利用有标注的训练数据，选择合适的算法，这样就可以学习模型了。这个模型告诉我们，在一篇文章里，那些词是关键字。那么，我之前使用的思路是什么呢？在语料充足的情况下，我们有很多统计量，比如卡方、平均值、标准差、余弦距离等等。那么用哪个统计量去描述关键词的特征最好呢？于是自然而然的想到了关键词提取，根据前人论文中提出的方法实现了。</p>

<p>这是两个解决问题的思路。不能说两个思路哪个好哪个坏，因为没什么可比性。这两种方法，前者立足于学习筛选关键字的标准，而后者立足于，我用什么样的标准，可以筛选出关键字。但是实践证明，解决我这个项目的问题，前者更好（Wikipedia Miner关键词挖掘效果很好）。因为在我的方法中，有个致命的弱点，就是语料。我是从一篇文章中根据统计规律去提取关键字，每个主题，使用什么词、什么词关键都满足一定的统计规律。那么语料不足怎么办？争取在不改变统计规律的前提下扩充语料，这一点太难做到了。而论文中的方法呢，学习的是标注关键字的方法，假定不论什么主题，哪些关键字重要，都是满足一定的准则的。显然后者更加符合维基百科的特点，详见<a href="http://en.wikipedia.org/wiki/Wikipedia:Manual_of_Style/Linking">维基百科规则</a></p>

<p>下面讨论第二个问题，其实是个知识面的问题。因为最终乐乐发现，在我们读的这篇论文描述前人工作的时候提到了关键字提取相关的技术，在一篇综述性的文献中。而论文的作者，正是在前人工作的基础上，提出了这种方法，在2008年。按理说过去这么久了，为什么我们在最初确定技术方案的时候，没有找到现在这个更好的解决方案呢？因为我们使用的谷歌学术中没有收录那篇文章，并且在最初我们对于这个领域比较陌生的时候，很难使用准确的关键字去在搜索引擎上搜索，所以也就比较难一下子就找到最好的解决方案。也是经过了一段时间的研究和摸索，机缘巧合下，我的导师给我推荐了Wikipedia Miner。我才发现我们的问题已经有了这么优秀的解决方案了。</p>

<p>仔细想想呢，这其实涉及到了领域知识的问题。用什么技术，解决什么问题，是要经过长期实践积累经验的。随着阅历的提升，知道的办法越多，就越有解决问题的能力。在这一点上，我的导师自然大大的超越了我们。不过如何更有效的利用各种学术资源，会议门户啊、学术搜索啊、学术数据库等等，回头我还是要好好向我的导师请教一下。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/23/summary-of-knowledge-visualization-project-stage-1/">知识可视化项目第一阶段小结</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-23T14:44:00+08:00" pubdate data-updated="true">Sep 23<span>rd</span>, 2013</time>
        
         | <a href="/blog/2013/09/23/summary-of-knowledge-visualization-project-stage-1/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>距离开始做数据可视化项目，已经过去了将近一个月的时间，目前项目的进展暂时告一段落，技术探索的工作基本完成，是个时候小结一下了。</p>

<p>目前项目的思路是这样的，以维基百科为数据源，将维基百科上的知识（目前以机器学习为例）用可视化的方式展现，提高学习和探索的效率。</p>

<p>具体来说，第一步。编写网页爬虫，从维基百科上下载数据，并且存储成结构化的数据（目前采用XML），存储的内容包括分类、关键词定义、页面关键词、参考文献。其中，关键词的定义，我们认为是维基百科词条页面的第一段，实际效果还不错，第一段文字往往能很好的直接阐释关键字的含义。页面关键词，就是那些本页面中比较重要的词，要想很好的了解本页面的内容，这些关键词对应的内容是非常重要的参考资料，在实现中，我们以页面内容中超链接的锚文字为基础，筛选那些链接指向的页面也包含本页关键字的链接锚文字，这一点是受到PageRank的思想所启发的；就效果来看，关键字筛选效果良好，但是这个条件明显太强了，在两个条件的限制下，大部分页面都只有7个以下的关键字，这样使得可视化的意义不大了，因为内容本来不多的情况下，单纯的文本就很容易理解的。参考文献，就是单纯是指维基百科词条页面中的参考文献，在目前的实现中，这些数据并没有加以利用。至于这些内容是如何从Web页面中提取的，主要靠对页面结构的分析，编写在网页爬虫的逻辑中。</p>

<p>第二步，是文本挖掘相关。针对上面的页面关键词，我们想要给每个页面关键词，根据相关度进行打分，然后根据这个相关度打分，进行进一步的可视化，比如比较重要的关键词Size比较大什么的。具体研究，使用了NLP中称为关键字提取（Keyword Extraction）的技术，通过阅读相关论文，确定了卡方相关性检验和仿PageRank的TextRank算法这两种技术方案。二选其一的话，我们选择了卡方检验，因为TextRank对我们来说有一些致命的缺点，比如计算量大、基于词在滑动窗口中的同时出现等等。相对来说，卡方检验对我们来说，要现实的多。</p>

<p>在我们参考的论文中，作者针对单篇论文，对关键字进行提取，打分自然就是卡方值。对语料数量的要求都不是特别高，但是对我们来说，我们现有的语料还是太少了，维基百科一般的词条页面中内容很少，用这些来进行关键词提取的话，估计效果甚微。于是我们决定扩充语料，经过研究，我们决定利用机器学习方面的会议(NIPS)及其提供的搜索引擎。因为项目做到这里我们已经决定先就一个词条，进行挖掘，实验下看下效果，所以就选了Machine_learning这个词条。扩充语料的过程还是用爬虫来完成的，模拟执行搜索引擎搜索，爬10篇论文下来作为语料。期间需要把pdf格式的转化成文本。经过一些折磨好歹完成语料的准备之后，开始进行关键词提取了，具体过程，一开始，我们想就第一步率先选出的关键字进行打分，算卡方值。但是语料准备好之后发现，我们选出的那些关键字，在这10篇论文中出现很少。究其原因，主要是我们扩充语料的思路有问题，试想维基百科中的词条，应该是比较宽泛的介绍性文字，而论文多是针对领域中某个小的问题的。从维基百科中挖掘出的关键词，很难应用到论文的语料中来。所以只能再次委曲求全，放弃对维基百科的关键字进行打分，改为直接从论文语料中进行关键词提取。</p>

<p>接下来的过程就是按照论文中的方法一步一步来了，涉及到词干提取，词组提取，词组聚类，计算卡方值等等。也顺利提取出了关键字，效果还不错。这么一来数据挖掘和准备的工作基本上就完成了。</p>

<p>第三步，可视化。可视化框架选择了D3js。用树状来表现分类，节点作为词条，点击词条，可视化展示此词条对应的关键词，使用了BubbleChart，主要涉及了D3js相关的javascript开发。</p>

<p>截止今天，以上的工作就是第一阶段做的事情。总的来说，没有成功的基于维基百科的数据进行挖掘，但是也探索了一条可行的路线，只是这条路线看样子扩展性并不好。于是，近几天忙于寻找一些更好的方式，不论是从数据源还是从挖掘的效果上。最近发现了一个专业的维基百科挖掘工具，(WikipediaMiner)[<a href="http://wikipedia-miner.cms.waikato.ac.nz/index.html">http://wikipedia-miner.cms.waikato.ac.nz/index.html</a>]和weka出自同一所大学，<a href="http://sepans.com/wikistalker/">效果</a>非常好。所以下一步，决定针对这个进行一些研究。先研究其原理，对比下我们挖掘的算法，看看差距在哪里，然后试图利用这个现有的工具，做一些工作。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/22/python-style-guide/">Python Style Guide</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-22T14:01:00+08:00" pubdate data-updated="true">Sep 22<span>nd</span>, 2013</time>
        
         | <a href="/blog/2013/09/22/python-style-guide/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>写Python一段时间了，由于从初学到现在，一直还在熟悉语法和各种数据结构，以事先功能为主，自觉代码写的非常丑陋，现在也写了不少Python代码了，是时候挑战下习惯，遵循合适的代码风格，写简单易读的代码，Be Pythonic!!</p>

<p>本文主要参考了《<a href="http://google-styleguide.googlecode.com/svn/trunk/pyguide.html">Google Python Style Guide</a>》、《<a href="http://programmers.stackexchange.com/questions/119913/how-can-i-learn-to-effectively-write-pythonic-code">How can I learn to effectively write Pythonic code</a>》、《<a href="http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html">Code Like a Pythonista: Idiomatic Python</a>》三篇文章，摘取了其中我现在可能需要遵循的，因为有些做比较大的系统的项目才用到的，暂时就没写。我主要以写小算法和小工具为主。</p>

<p>一、编码风格：</p>

<p>1、不要使用分号，也不要利用分号把两个命令放在一行</p>

<p>2、每行代码不超过80（特殊情况下，尽量不要把链接分开两行放）</p>

<p>3、少用括号，条件语句和return语句不要用括号（特殊情况下，利用括号来进行断行可以）</p>

<p>4、缩进用四空格（一般在文本编辑器里设置tab转四空格）</p>

<p>5、空格使用。语法符号之后用空格，但是括号、花括号、方括号之后不要用。逗号冒号之后有个空格，但是之前不要有。赋值号前后有空格，但是在使用默认参数的时候，不要加。</p>

<p>6、一系列的赋值或者相同的操作。没必要用空格来使赋值号对齐。</p>

<p>7、字符串的使用。尽量使用string format和&#8217;%&lsquo;而不是&rsquo;+&lsquo;。在循环中构造字符串的时候，不要使用&rsquo;+&lsquo;和&rsquo;+=&lsquo;，而是把所有的字符串先存在一个list里，然后在循环结束之后，用join函数。（这一点需要格外注意，具体原因原文有）</p>

<p>8、多行string尽量不要用三个连续的引号，因为会破坏整体的缩进。使用join函数拼接。</p>

<p>9、file和socket使用完毕要显式关闭</p>

<p>10、临时的实现临时插入的代码，使用TODO注释</p>

<p>11、import的组织。每行一个，不要一次import多个。按照标准库、第三方库、程序特有的，这一顺序进行引用，统一级别按照字母顺序排序。</p>

<p>12、命名规范。module_name, package_name, ClassName, method_name, ExceptionName, function_name, GLOBAL_CONSTANT_NAME, global_var_name, instance_var_name, function_parameter_name, local_var_name。大部分使用了小写和下划线。</p>

<p>13、所有的脚本都应该是可import的，并且脚本被import之后，不能对当前脚本的功能有所影响。所以，脚本都应该有主函数！</p>

<pre><code>def main():
    …
if __name__ == '__main__':
    main()
</code></pre>

<p>不然的话，主程序的逻辑，会在被import的时候被执行。</p>

<p>14、注释。使用正确的注释方法。见原文。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/22/preprocessing/">打表与预处理</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-22T13:31:00+08:00" pubdate data-updated="true">Sep 22<span>nd</span>, 2013</time>
        
         | <a href="/blog/2013/09/22/preprocessing/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>在ACM编程中，俗称打表，学名预处理。是我最近学习到的一个编程技巧。思想很简单自然，就是当有多组测试数据，但是每组测试数据的计算过程都是一模一样的。这时候，为了提高效率，节省计算资源，就会使用打表。</p>

<p>举例说明，计算斐波那契数列，可能要求输出第30-100项。算法中，我们会自底向上计算，也就是从第1项一直计算到第n项。每计算一项，都是重复这个过程。假如不对算法进行优化的话，我们计算第30项，要从第1项计算过来，计算第100项的时候，还要再从第一项计算一遍，这种情况下，就浪费计算资源了！</p>

<p>对于这种问题的优化思路，就是事先计算好所有可能需要输出的项，比如题目限制n&lt;=10000，那就把前10000项的斐波那契数列都计算好，存在数组里，然后根据测试用例的要求，输出对应的项就好了。</p>

<p>这种计算一次使用多次的思想，与动态规划非常相似。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/14/chi-square-information-gain-and-mutual-information/">卡方校验、信息增益和互信息</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-14T20:51:00+08:00" pubdate data-updated="true">Sep 14<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/09/14/chi-square-information-gain-and-mutual-information/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>从一开始做文本分类到现在做的项目，一直在不断的学习新的知识，练习已经掌握的工具，也越来越深刻的认识到，“你所掌握的机器学习方法，并不是死板的一成不变的算法，而是一个一个的小工具，是解决问题的思路”。</p>

<p>这篇博客将对比三个在我进行文本挖掘相关工作的时候经常用到的小工具，以及我对他们的认识，仅限个人的粗浅观点，也是我当前的认识，不见得正确。</p>

<p><a href="http://zh.wikipedia.org/wiki/%E7%9A%AE%E7%88%BE%E6%A3%AE%E5%8D%A1%E6%96%B9%E6%AA%A2%E5%AE%9A">卡方校验</a></p>

<p>首先理解卡方校验的概念，除了维基百科，我总会看<a href="http://www.blogjava.net/zhenandaci/archive/2008/08/31/225966.html">这篇博客</a>。简单来讲，卡方校验是用来判别两个事件是否相关的方法，因此在特征提取、关键词提取中都有很多的应用。基本思路是，首先假设A、B不相关，然后根据A和B的联合概率分布，计算卡方值，公式在定义中都有给出，卡方值越大，越倾向于推翻原假设，也就是A、B越相关。在计算卡方值的过程中，最关键的问题是找到联合概率分布。那么我们应该如何理解卡方值呢？卡方值的含义其实是这样的，我们首先假设A、B不相关，也就是AB相互独立，那么我们可以为联合概率分布中的AB同时成立的事件计算期望值，根据定义公式显示，卡方值是这个期望值和实际值之间的差的平方除以期望值的和（定义和方差很像！），衡量了这两个量拟合的程度。那么，卡方值越大，代表期望值和实际值之间的差越大，也就是我们计算期望值所依赖的假设，是不成立的！</p>

<p>当我们想用卡方检验的方法，去判断两个事件是否相关的时候，理解问题的过程，就是建立事件A、B联合概率分布的过程，找到这个概率分布，就可以计算卡方值。举例说明的话，在文本分类的特征提取这一步，事件A是特征词w是否存在在本篇文档中，事件B是本篇文档是否属于类c。首先假设“w不是类c的特征词”，那么词w在属于类c的所有文档中出现的概率，应当与w在全部文档中出现的概率相同，我们依据这一假设，可以算出w出现在c类的文档数的期望，用期望值和实际值的差的平方除以作为卡方值。</p>

<p><a href="http://zh.wikipedia.org/wiki/%E7%9B%B8%E5%AF%B9%E7%86%B5">信息增益</a></p>

<p>也经常作为特征提取的方法，也用来衡量两个事件的相关性，但是是从信息论的角度来的。信息论用熵来衡量信息量。信息增益，简单理解就是在已知条件B的情况下，事件A的信息量的改变程度，就是熵的改变程度。同样有<a href="http://www.blogjava.net/zhenandaci/archive/2009/03/24/261701.html">一篇博客</a>讲得很透彻。从上面的描述可以看出，计算信息增益的关键是计算熵和条件熵。所以说，信息增益对应的概率分布，是普通的概率分布和一个条件概率分布。那么我们应该如何具体理解信息增益呢？我们首先计算事件A的信息熵，然后考虑事件B，计算在有事件B的情况下的条件熵，两者之差，就是信息熵的改变，改变越大，说明事件B对于事件A的相关性越大。由于涉及到信息论，所以信息量改变这一点，就变的略显抽象。</p>

<p>仿照上文中对卡方校验的介绍。利用信息增益解决问题的关键，在于找到这个条件概率分布，以计算条件熵。同样举文本分类中特征提取这个例子。事件A是指文档属于类ci，事件B是词w是否出现在文档中。根据P(Ci|w)和P(Ci|^w)这两个条件概率分布，可以计算条件熵H(C|T)。</p>

<p>不过仔细读过信息增益的概念，发现我们上面介绍的和KL散度差别挺大的，目前我也不能理解这两种概念是否本质上相同，但是在分类和挖掘领域，大家一般是像我说的那样去理解信息增益的。</p>

<p><a href="http://zh.wikipedia.org/wiki/%E4%BA%92%E4%BF%A1%E6%81%AF">互信息</a></p>

<p>在互信息定义的多条公式中，我一般使用第三个，就是X，Y熵之和减去联合熵。根据联合熵，就可以发现，决定互信息的，也是一个联合概率分布。</p>

<p>比较形象的理解互信息的公式方法是，认为事件X和事件Y相关，可以让总信息熵减少多少，差别越大，X和Y越相关。计算互信息的关键，是计算联合熵，因此在用互信息解决问题的适合，找到这个联合概率分布，是核心。不要试图去寻找其他的概率分布，实践表明，互信息的联合概率分布与卡方检验的非常相似，都是x是否怎样，y是否怎样。同样以文本分类为例，X为文档是否属于类c，Y事件为文档是否包含w，然后利用这个概率分布去计算联合熵。这么一看，和卡方检验几乎完全相同！只是利用了不同的理论基础。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/09/02/dynamic-programming/">动态规划</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-09-02T19:53:00+08:00" pubdate data-updated="true">Sep 2<span>nd</span>, 2013</time>
        
         | <a href="/blog/2013/09/02/dynamic-programming/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>当遇到复杂问题的时候，我们很自然的想要降低问题的复杂度和规模。在《算法导论》中，作者将动态规划和分治算法都当做降低问题规模，将复杂问题转化为子问题的方法。不同的是，分治算法划分出的子问题都是独立的，而动态规划中的子问题相互之间是非独立的，高层的子问题（离原问题比较近）往往依赖于低层子问题。所以假如不利用动态规划，自底向上计算这类问题的时候，会有大量重复的计算，从而使算法的效率低。</p>

<p>那么，动态规划的本质就是建立一个表，存储子问题的结果，在计算高层问题的时候，直接利用表中的结果。这就是动态规划的基本思想。动态规划往往被用来计算最优化问题，利用的理论是子问题最优化理论，也就是一个最优化解的路径上的所有子问题，也都是当前最优化的。但是，这已经不是动态规划的核心了，我之前就在理解动态规划的时候，犯了这个错误。在试图利用动态规划去解决问题的时候，我往往纠结于去寻找这样的最优化子结构。其实有时候，这种最优化子结构并不好找甚至没有，但是也可以利用动态规划去解。动态规划的基本思想，还是很朴素的。</p>

<p>最近在TopCoder上读了一个黄名大牛写的<a href="http://www.topcoder.com/tc?d1=tutorials&amp;d2=dynProg&amp;module=Static">动态规划进阶手册</a>深受启发。文中指出，动态规划应该这么描述：动态规划算法往往建立在一个递归方程和这个方程的初始状态之上（很像那种找递推公式的问题）。每个子问题，都建立在之前发现并计算好的问题上。动态规划问题往往都有多项式级别的复杂度，因此比暴力搜索和回溯算法效率要高（这一点我还不是特别明白，文中有提出，多项式复杂度的问题都可以用动态规划来解决）。</p>

<p>动态规划问题的解决过程是分为两步：定义问题的状态（或者说是子问题），发现如何又一个状态转移到下一个状态（也就是定义状态转移方程，是上文指出的“递归方程”），更准确的说，如何利用已有的子状态，计算下一个状态，因为有时候不是从i转移到i+1。</p>

<p>举例说明：</p>

<p>给定N个硬币，价值分别为（v1，v2，v3&hellip;vN），给定价值和S。求解价值和为S的硬币集合，使其包含的硬币个数最少，每种价值的硬币可以使用任意多个。</p>

<p>问题分析：</p>

<p>在这个问题中我们要求解的结果是价值和S，那么定义“状态”为当前价值和为i（i&lt;S），对于所有的状态j（j>i），要利用i来求解，而对于状态j(j&lt;i)，要在计算状态i之前计算好。在实践中，我发现子状态往往是针对要求解的那个问题的。</p>

<p>对于状态i，我们假设，所有的子状态j（j&lt;i）都已经计算出结果来了。那么i如何利用子结果来计算。对于所有价值小于i 的硬币（循环遍历）j，使用此硬币，使价值和变为i-j，由于i-j&lt;i，那么此子问题，我们应该已经计算好了，假设硬币数为m，则i状态的结果应为m+1。遍历过程中，我们把最小的那个结果存给状态i。</p>

<p>基于这种想法，我们需要从状态0开始，到状态s逐一计算。也就是动态规划中所谓的，从顶向下思考，从底向上计算。这里有个思考陷阱，千万不要想如何从i计算i+1，而是如何利用已有的所有子状态j(j&lt;=i)计算i+1。就写这篇博客的过程，我因为想当然认为这样，差点进入死胡同。</p>

<p>这是动态规划最基本的思考过程。</p>

<p>一般情况下，我们要遍历所有的比i低的状态j，但是并不是所有的j都能转换到i。在这个硬币问题中取决于，是否有个硬币k，使得S[j]+vk=S[i]。这就是状态转移的条件，所以在实践中，我们一般要判断状态j能否转移到条件i，在上例中没有判断的原因是，我们根据硬币价值遍历，遍历到的都肯定满足转移的条件。其他问题，比如无向图中，状态节点j能否转移到节点i取决于i和j之间是否有一条边。这就要判断了，当然假如存储图结构的时候，存储了所有指向节点i的入节点j，就可以遍历这个节点集了，但是对于自底向上的动态规划解决方案中，很少出现。</p>

<p>更复杂一点，状态转移不是一维的，变成二维甚至多维（目前只见过二维）。这种问题，通过比较好的定义子状态，也很好理解。</p>

<p>还有其他的情况下，限制条件所需的信息和我们所求的结果并不一致。比如赋权图中，从节点j到节点i的最短路径，在权值和小于s的前提下。我们最终关心的是路径长度，但是状态转移的限制条件是权值和，这时候需要一个二维数组来存储。</p>

<p>更复杂的情况，乍一看并不是动态规划问题，但是和我们以前遇到过的动态规划问题很像，这时候，我们需要一些转变，把问题转换成以前的问题的升级版去求解。这是最难的，菜鸟级别的我暂时还没什么感受。留在日后补充吧。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/08/26/tooltips-on-mouse-hover-using-d3/">为控件增加鼠标悬浮提示</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-08-26T14:21:00+08:00" pubdate data-updated="true">Aug 26<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/08/26/tooltips-on-mouse-hover-using-d3/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>上星期阅读了《Interactive Data Visualization for the Web》一书之后，便开始尝试使用D3js了。以前一直没怎么写过前端和界面，个人对于坐标位置布局什么的相当没感觉，总是乱乱的。所以这次写来，大部分也都是用的别人写好的现成的东西，在这个基础上做些改动。</p>

<p>今天做的改动之一就是为标签Text增加鼠标悬浮事件，提示改概念的定义。</p>

<p>效果图如下：</p>

<p><img src="http://i.imgur.com/0E53nrC.jpg" alt="Imgur" /></p>

<p>这段代码参考了StackOverflow上的这个<a href="http://stackoverflow.com/questions/10805184/d3-show-data-on-mouseover-of-circle">帖子</a></p>

<pre><code>// Show defination of the current item
function show_defination(d) {
    d3.select(this)
        .append("svg:title")
        .text(function(d) {return d.def;})
        .attr("x",function(d) {return d.x+10;})
        .attr("y",function(d) {return d.y+10;})
}
</code></pre>

<p>我添加的代码如上，绑定在text控件的mouseover时间上。<code>on("mouseover",show_defination);</code></p>

<p>另外我还发现了一个很好的在线校验json的<a href="http://jsonlint.com/">网站</a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/08/20/recursion-problem-and-hmm-model/">ACM中递归问题解决方法思考</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-08-20T21:47:00+08:00" pubdate data-updated="true">Aug 20<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/08/20/recursion-problem-and-hmm-model/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>最近在做ACM的练习题来练习编程的基本功，今天研究到了递归问题。就是通过寻找递推公式，来解决问题。</p>

<p>在总结方法的过程中，发现，对于一些比较简单的题目，可以在纸上比较轻易的模拟过程的问题，可以通过观察第n项与前面的1-3项之间的关系，直接得到递推公式。</p>

<p>比如：</p>

<p><a href="http://acm.hdu.edu.cn/webcontest/contest_showproblem.php?pid=1001&amp;ojid=0&amp;cid=1531&amp;hide=0">超级楼梯</a></p>

<p><a href="http://acm.hdu.edu.cn/webcontest/contest_showproblem.php?pid=1002&amp;ojid=0&amp;cid=1531&amp;hide=0">一只小蜜蜂&hellip;</a></p>

<p>这些问题都比较简单直观，所以很容易思考直接获得递推公式。</p>

<p>而其他的一些问题，可能就相对来说抽象一些，需要我们画图，找一下规律，这时候千万不要怕麻烦，画图可以很直观的帮助我们找到规律，也就是递推公式。</p>

<p><a href="http://acm.hdu.edu.cn/webcontest/contest_showproblem.php?pid=1004&amp;ojid=0&amp;cid=1531&amp;hide=0">骨牌铺方格</a></p>

<p><a href="http://acm.hdu.edu.cn/webcontest/contest_showproblem.php?pid=1009&amp;ojid=0&amp;cid=1531&amp;hide=0">Tiling_easy version</a></p>

<p>比如上面这种铺砖的，画图之后，有目的的去观察，有n-1和n-2项如何去铺砖得第n项，就可以发现递推公式。这种一般从第三项之后，才会有规律。也就是找第四项和第三、第二项之间的关系。</p>

<p>总而言之，这类问题考验思维能力要强于对编程能力的考验。思考的方法更为重要。我大体总结了一下，这类问题主要有两种思考的方式，一种是从前往后，一种是从后往前。</p>

<p>从前往后，就是考察第一、第二项，这一般是递推公式的初始项，然后考察第三项、第四项、第五项，在计算这几项的时候，看能否提出一种可以推广的计算方法，这种方法，抽象来，就是递推公式。这种方法的优点是，比较直观，可以画图，容易理解，缺点是，有些问题没法解决。</p>

<p>从后往前，就是直接考察第n项的得出，有几种可能来构造第n项，每种可能如何用第n-1项、第n-2项的值，来构造。这种方法的优点是通用性更高一些，只要脑筋转的过来，大部分问题都可以通过这种方法找出递推公式。缺点就是比较抽象，不怎么好想。</p>

<p>写到这里，我觉得这种问题的解决，好像是HMM中的前向算法和后向算法，分别就是从前向后和从后向前，进行状态的转移。不过再仔细思考，这也只是形似而已，似乎在本质上，双方没有数学层面上的必然联系。</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/08/19/my-general-view-on-data-visualization/">对数据可视化的初步认识</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-08-19T14:06:00+08:00" pubdate data-updated="true">Aug 19<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/08/19/my-general-view-on-data-visualization/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>先说点废话，导师是研究数据可视化方向的，所以平时在实验室的工作大部分是和数据可视化相关联的。每天至少也会花六七个小时在相关的方面。大四一年七七八八做了很多项目，很少有和数据可视化相关的，个人感觉也都没啥技术含量，觉得大四一年基本上白忙活了，自己也没提高多少。研一的时候开始接触了数据挖掘和机器学习，也去公司实习，学习了很多这方面的知识，对这个方向也有了大致的了解，非常喜欢，很有些相见恨晚的感觉。为什么呢？主要是惊诧于数据的强大力量。说到数据的价值，其实一堆一堆的数字、文字等等，是没什么价值的，价值在于数据中蕴含的信息。</p>

<p>机器学习和数据挖掘，就是这样的工具，可以把信息，从浩瀚的数据海洋中提取出来。海量数据的信息处理，就是最近很火的“大数据”了。在未来，互联网向各个传统行业，我们生活的方方面面不断渗透的过程中，数据挖掘和机器学习的方法，是可以做很多很多的事情的。</p>

<p>再说数据可视化，以前的时候理解一直很不到位，一直觉得数据可视化，就是用一种很好的方式，来展现信息，表达观点，这样可以提高沟通的效率，也很符合人的认知习惯。那么数据可视化，应该技术含量很低，更多的是个经验学科，自己领域里的数据，一般用什么样的形态来表示，这个从业时间长了，自己就了解了。这两天在看《Interative Data Visualization for the Web》这本书（中文好像叫《D3js实战》么？），只看了一点，就有很大收获。但从对数据可视化的由来和认识来讲，感觉作者理解的好深刻。数据可视化分为解释性的可视化（explainatory）和探索性的可视化（exploratory）。前者就是我一直认为的那样，而后者我导师一般说是“可视分析”，通过提供对数据的交互手段，帮助人们挖掘知识、信息。</p>

<p>那么数据可视化和数据挖掘机器学习应当是有着非常密切的关系的。先说解释性的可视化。一般来讲，我们说数据挖掘机器学习是非常强大的工具，可以帮助我们从数据中学习，以进行分类、回归、聚类等工作，解决实际问题。那么挖掘出来的信息，需要交流和传递，才能有产生价值，这时候，数据可视化可以帮助你，更好地把你想表达的信息传递出去。那么可视分析呢，意义在于，有些问题，数据挖掘可能帮不上忙，但是人们的长期工作以来，经验积累，有很多先验知识，这些知识一般比较难在数据挖掘的过程中有所帮助。那么可视分析就可以帮助这些有经验的人士，更好的操作数据，可以快速的产生数据的不同视图，让其他行业的专家也可以享受到挖掘的福利。这方面，美国已经有企业做的很成熟了，公司也都上市了，Tableau。回头我也要试用学习一下。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Categories</h1>
    <ul id="category-list"><li><a href='/blog/categories/codesegment/'>CodeSegment (1)</a></li><li><a href='/blog/categories/hadoop/'>Hadoop (1)</a></li><li><a href='/blog/categories/shu-ju-ke-shi-hua/'>数据可视化 (3)</a></li><li><a href='/blog/categories/wen-ben-wa-jue/'>文本挖掘 (3)</a></li><li><a href='/blog/categories/ji-qi-xue-xi/'>机器学习 (4)</a></li><li><a href='/blog/categories/za-xiang/'>杂项 (2)</a></li><li><a href='/blog/categories/sheng-huo/'>生活 (1)</a></li><li><a href='/blog/categories/suan-fa-ji-chu/'>算法基础 (4)</a></li><li><a href='/blog/categories/bian-cheng-yu-yan/'>编程语言 (1)</a></li></ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/09/28/hadoop-first-trial/">Hadoop环境搭建小结</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/24/summary-of-wikivis-project-2/">知识可视化项目第一阶段总结2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/23/summary-of-knowledge-visualization-project-stage-1/">知识可视化项目第一阶段小结</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/22/python-style-guide/">Python Style Guide</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/22/preprocessing/">打表与预处理</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/xutianming">@xutianming</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'xutianming',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>




<section>
  <h1>Tag Cloud</h1>
    <span id="tag-cloud"><a href='/blog/categories/codesegment' style='font-size: 115.0%'>CodeSegment(1)</a> <a href='/blog/categories/hadoop' style='font-size: 115.0%'>Hadoop(1)</a> <a href='/blog/categories/数据可视化' style='font-size: 145.0%'>数据可视化(3)</a> <a href='/blog/categories/文本挖掘' style='font-size: 145.0%'>文本挖掘(3)</a> <a href='/blog/categories/机器学习' style='font-size: 160.0%'>机器学习(4)</a> <a href='/blog/categories/杂项' style='font-size: 130.0%'>杂项(2)</a> <a href='/blog/categories/生活' style='font-size: 115.0%'>生活(1)</a> <a href='/blog/categories/算法基础' style='font-size: 160.0%'>算法基础(4)</a> <a href='/blog/categories/编程语言' style='font-size: 115.0%'>编程语言(1)</a> </span>
</section>

  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Xutianming -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'xutianming';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
