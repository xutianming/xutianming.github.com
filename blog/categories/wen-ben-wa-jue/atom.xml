<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 文本挖掘 | Xutianming Blog]]></title>
  <link href="http://xutianming.github.io/blog/categories/wen-ben-wa-jue/atom.xml" rel="self"/>
  <link href="http://xutianming.github.io/"/>
  <updated>2013-08-26T14:37:54+08:00</updated>
  <id>http://xutianming.github.io/</id>
  <author>
    <name><![CDATA[Xutianming]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[文本分类实践]]></title>
    <link href="http://xutianming.github.io/blog/2013/07/19/text-classification-in-action/"/>
    <updated>2013-07-19T22:14:00+08:00</updated>
    <id>http://xutianming.github.io/blog/2013/07/19/text-classification-in-action</id>
    <content type="html"><![CDATA[<p>学习机器学习有一阵子了，先是仔细阅读了《统计学习方法》这本书，对目前比较流行的统计学习方法和模型有了大致的认识，比如朴素贝叶斯、逻辑斯蒂回归、支持向量机、隐马尔科夫模型等等。但是仅仅有理论上的认识是不够的，关键还是指导实践解决问题。</p>

<p>先前在百度实习的时候，已经对机器学习有了初步的认识，并且当时也利用逻辑斯蒂回归训练了一个还算不错的模型，虽然最终由于时间原因，没有做成一个可以应用到线上的模块，但是对于我对机器学习的这第一次尝试，我还是很满意的，当时也决定在研二的这一年里，好好研究一下机器学习相关的东西，以后好找相关方向的工作。</p>

<p>最初的实践决定从文本分类开始，因为这个领域相对来说研究的比较成熟，并且在工业界仍然有很多很重要的应用。由于svm一直是个非常重要的机器学习模型，之前对原理有一定的了解，于是决定从使用svm开始。网上相关的教程很多，我也是慢慢参考着别人的方法一步一步尝试。这里主要记录下我实践的过程，以供日后参考。</p>

<p>文本分类大致分为以下几步：</p>

<ul>
<li>数据预处理（一般是分词，去停）</li>
<li>特征选择（比较好的方法有卡方校验和信息增益）</li>
<li>特征值确定（比较好的是tf-idf值）</li>
<li>特征向量计算</li>
<li>模型训练</li>
<li>模型测试</li>
</ul>


<p>我使用的是复旦大学自然语言理解实验室提供的预料，选取了computer、agriculture、sports和history，选择分类的时候特意选择了差别比较大的几类，这样可以在某种程度上提高分类效果吧。</p>

<p>首先是数据预处理，我使用了同事推荐了一个分词工具，分词的效果不是很好，算是个初级的分词工具，基于python的，使用起来非常简单。分词之后，把预料中的文章，处理成了一个词一行的文档，便于下一步的处理。</p>

<p>数据预处理之后，就是选择特征了，这里所谓的“特征”，就是上一步分出来的一个一个的词，每个词都可以说是一个特征，但是把每个特征都哪来使用，显然是不现实的，太高维的特征向量，首先训练起来比较费时，另外会使模型复杂度提升从而容易使svm训练过拟合。我训练的时候，本想使用1w维的特征，最终使用了7600左右的特征，具体的我后面会说。考虑到以上原因，所以要有个特征选择的过程，也就是选择那些可以很好的区分每一类的词，比如包含了“农业”一词的文章，属于农业类的可能性比较大，所以这样的词，就算是好特征。那么如何筛选出这些特征呢，要有个数学上的量，来衡量特征的好坏，可供选择的有互信息、信息增益、卡方校验等方法。其中互信息的效果比较差，我就没自己尝试，我先后使用了信息增益和卡方校验的方法。</p>

<p>卡方校验，学名是“皮尔森卡方检验”，是一种假设检验方法。首先，我们的假设是“词word和类class不相关”，然后针对包含word的文档和以及属于class的文档的联合分布，算卡方值，每类选择卡方值最大的2500个值，去作为特征值，因为卡方值越大，倾向于原假设为假，也就是说，卡方值越大，词word和类class越相关，这个词就是我们要找的好特征。为啥是2500个值，因为我初步决定选择1w个特征么，一共四类，每一类选择2500个。最终计算下来，因为分词效果的原因，很多单字的特征被筛选出来，但是单字的信息非常少，我觉得不足以作为一个好的特征，所以我对于筛选出来的1w个特征，去除了那些单字的词，就剩下了大约7600个词作为特征。</p>

<p>特征选择出来之后，我们要利用这些特征去表示要分类的文档，也就是所谓的“把文档映射到特征空间”，用向量来表示文档。这里会遇到一个问题，如何用特征表示文档，另外每个特征对于一个文档都是等同重要的嘛？这里就自然涉及到为特征赋权重。我是用的是tf-idf值。选择这个的原因是，卡方校验有个缺陷，就是“低频率缺陷”，那些在一篇文档里只出现过一次的词，也有可能会有很大的卡方值，但是这个词，对这篇文章可能没太大价值，那些只在某一类文章中大量出现，而在其他类中很少出现的词，才是决定类别的词。而我个人认为tf-idf值可以比较好的弥补这一缺陷。当然我只是定性分析，我不太懂数学上的证明，也没去查阅相关的资料。</p>

<p>如此一来，我们把文档用特征向量来表示了，接下来就是训练模型了。在上述过程的实现过程中，我没有遇到太大的问题，unix+python是很有利的文本处理工具，实现起来很快。我是用的svm工具是libsvm，使用也很简单，但是我确实在训练模型的时候遇到了一个问题。</p>

<p>一般来讲，libsvm的使用流程是这样的：</p>

<ul>
<li>svm-scale，对数据进行归一化处理，映射到[0,1]区间内</li>
<li>grid.py 寻找最优参数c和g</li>
<li>svm-train</li>
<li>svm-predict</li>
</ul>


<p>我第一次使用的时候，用信息增益选择特征，libsvm不太懂，也没去查太多的资料，略去了第二步，也就是我训练的时候没指定参数。这训练效果太差了，把所有的文档都分到了一类中。一开始我总怀疑特征提取的不好，于是换卡方校验，结果还是这样，之后开始怀疑我训练的方法不对，于是很快发现了问题。在指定c和g参数之后，训练结果非常好，对训练数据的准确率为100%，在测试集上的准确率为93.52%，比人家论文上的准确率还高，非常让人振奋。</p>

<p>至此，算是完满的完成了一次svm文本分类的实践，结果也符合之前给自己定的目标90%以上的准确率。接下来，我会根据这次实践的结果，总结分析，再回归到svm的理论上，比如c和g具体含义对应的是什么，借此机会深入理解svm，好更好的掌握这个工具的使用。然后还会再用同样的方法，实践体会其他的分类模型，比如逻辑斯蒂回归、神经网络等等。</p>
]]></content>
  </entry>
  
</feed>
