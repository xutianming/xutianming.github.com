<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: 数据可视化 | Xutianming Blog]]></title>
  <link href="http://xutianming.github.io/blog/categories/shu-ju-ke-shi-hua/atom.xml" rel="self"/>
  <link href="http://xutianming.github.io/"/>
  <updated>2013-09-28T16:17:21+08:00</updated>
  <id>http://xutianming.github.io/</id>
  <author>
    <name><![CDATA[Xutianming]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[知识可视化项目第一阶段小结]]></title>
    <link href="http://xutianming.github.io/blog/2013/09/23/summary-of-knowledge-visualization-project-stage-1/"/>
    <updated>2013-09-23T14:44:00+08:00</updated>
    <id>http://xutianming.github.io/blog/2013/09/23/summary-of-knowledge-visualization-project-stage-1</id>
    <content type="html"><![CDATA[<p>距离开始做数据可视化项目，已经过去了将近一个月的时间，目前项目的进展暂时告一段落，技术探索的工作基本完成，是个时候小结一下了。</p>

<p>目前项目的思路是这样的，以维基百科为数据源，将维基百科上的知识（目前以机器学习为例）用可视化的方式展现，提高学习和探索的效率。</p>

<p>具体来说，第一步。编写网页爬虫，从维基百科上下载数据，并且存储成结构化的数据（目前采用XML），存储的内容包括分类、关键词定义、页面关键词、参考文献。其中，关键词的定义，我们认为是维基百科词条页面的第一段，实际效果还不错，第一段文字往往能很好的直接阐释关键字的含义。页面关键词，就是那些本页面中比较重要的词，要想很好的了解本页面的内容，这些关键词对应的内容是非常重要的参考资料，在实现中，我们以页面内容中超链接的锚文字为基础，筛选那些链接指向的页面也包含本页关键字的链接锚文字，这一点是受到PageRank的思想所启发的；就效果来看，关键字筛选效果良好，但是这个条件明显太强了，在两个条件的限制下，大部分页面都只有7个以下的关键字，这样使得可视化的意义不大了，因为内容本来不多的情况下，单纯的文本就很容易理解的。参考文献，就是单纯是指维基百科词条页面中的参考文献，在目前的实现中，这些数据并没有加以利用。至于这些内容是如何从Web页面中提取的，主要靠对页面结构的分析，编写在网页爬虫的逻辑中。</p>

<p>第二步，是文本挖掘相关。针对上面的页面关键词，我们想要给每个页面关键词，根据相关度进行打分，然后根据这个相关度打分，进行进一步的可视化，比如比较重要的关键词Size比较大什么的。具体研究，使用了NLP中称为关键字提取（Keyword Extraction）的技术，通过阅读相关论文，确定了卡方相关性检验和仿PageRank的TextRank算法这两种技术方案。二选其一的话，我们选择了卡方检验，因为TextRank对我们来说有一些致命的缺点，比如计算量大、基于词在滑动窗口中的同时出现等等。相对来说，卡方检验对我们来说，要现实的多。</p>

<p>在我们参考的论文中，作者针对单篇论文，对关键字进行提取，打分自然就是卡方值。对语料数量的要求都不是特别高，但是对我们来说，我们现有的语料还是太少了，维基百科一般的词条页面中内容很少，用这些来进行关键词提取的话，估计效果甚微。于是我们决定扩充语料，经过研究，我们决定利用机器学习方面的会议(NIPS)及其提供的搜索引擎。因为项目做到这里我们已经决定先就一个词条，进行挖掘，实验下看下效果，所以就选了Machine_learning这个词条。扩充语料的过程还是用爬虫来完成的，模拟执行搜索引擎搜索，爬10篇论文下来作为语料。期间需要把pdf格式的转化成文本。经过一些折磨好歹完成语料的准备之后，开始进行关键词提取了，具体过程，一开始，我们想就第一步率先选出的关键字进行打分，算卡方值。但是语料准备好之后发现，我们选出的那些关键字，在这10篇论文中出现很少。究其原因，主要是我们扩充语料的思路有问题，试想维基百科中的词条，应该是比较宽泛的介绍性文字，而论文多是针对领域中某个小的问题的。从维基百科中挖掘出的关键词，很难应用到论文的语料中来。所以只能再次委曲求全，放弃对维基百科的关键字进行打分，改为直接从论文语料中进行关键词提取。</p>

<p>接下来的过程就是按照论文中的方法一步一步来了，涉及到词干提取，词组提取，词组聚类，计算卡方值等等。也顺利提取出了关键字，效果还不错。这么一来数据挖掘和准备的工作基本上就完成了。</p>

<p>第三步，可视化。可视化框架选择了D3js。用树状来表现分类，节点作为词条，点击词条，可视化展示此词条对应的关键词，使用了BubbleChart，主要涉及了D3js相关的javascript开发。</p>

<p>截止今天，以上的工作就是第一阶段做的事情。总的来说，没有成功的基于维基百科的数据进行挖掘，但是也探索了一条可行的路线，只是这条路线看样子扩展性并不好。于是，近几天忙于寻找一些更好的方式，不论是从数据源还是从挖掘的效果上。最近发现了一个专业的维基百科挖掘工具，(WikipediaMiner)[<a href="http://wikipedia-miner.cms.waikato.ac.nz/index.html">http://wikipedia-miner.cms.waikato.ac.nz/index.html</a>]和weka出自同一所大学，<a href="http://sepans.com/wikistalker/">效果</a>非常好。所以下一步，决定针对这个进行一些研究。先研究其原理，对比下我们挖掘的算法，看看差距在哪里，然后试图利用这个现有的工具，做一些工作。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[为控件增加鼠标悬浮提示]]></title>
    <link href="http://xutianming.github.io/blog/2013/08/26/tooltips-on-mouse-hover-using-d3/"/>
    <updated>2013-08-26T14:21:00+08:00</updated>
    <id>http://xutianming.github.io/blog/2013/08/26/tooltips-on-mouse-hover-using-d3</id>
    <content type="html"><![CDATA[<p>上星期阅读了《Interactive Data Visualization for the Web》一书之后，便开始尝试使用D3js了。以前一直没怎么写过前端和界面，个人对于坐标位置布局什么的相当没感觉，总是乱乱的。所以这次写来，大部分也都是用的别人写好的现成的东西，在这个基础上做些改动。</p>

<p>今天做的改动之一就是为标签Text增加鼠标悬浮事件，提示改概念的定义。</p>

<p>效果图如下：</p>

<p><img src="http://i.imgur.com/0E53nrC.jpg" alt="Imgur" /></p>

<p>这段代码参考了StackOverflow上的这个<a href="http://stackoverflow.com/questions/10805184/d3-show-data-on-mouseover-of-circle">帖子</a></p>

<pre><code>// Show defination of the current item
function show_defination(d) {
    d3.select(this)
        .append("svg:title")
        .text(function(d) {return d.def;})
        .attr("x",function(d) {return d.x+10;})
        .attr("y",function(d) {return d.y+10;})
}
</code></pre>

<p>我添加的代码如上，绑定在text控件的mouseover时间上。<code>on("mouseover",show_defination);</code></p>

<p>另外我还发现了一个很好的在线校验json的<a href="http://jsonlint.com/">网站</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[对数据可视化的初步认识]]></title>
    <link href="http://xutianming.github.io/blog/2013/08/19/my-general-view-on-data-visualization/"/>
    <updated>2013-08-19T14:06:00+08:00</updated>
    <id>http://xutianming.github.io/blog/2013/08/19/my-general-view-on-data-visualization</id>
    <content type="html"><![CDATA[<p>先说点废话，导师是研究数据可视化方向的，所以平时在实验室的工作大部分是和数据可视化相关联的。每天至少也会花六七个小时在相关的方面。大四一年七七八八做了很多项目，很少有和数据可视化相关的，个人感觉也都没啥技术含量，觉得大四一年基本上白忙活了，自己也没提高多少。研一的时候开始接触了数据挖掘和机器学习，也去公司实习，学习了很多这方面的知识，对这个方向也有了大致的了解，非常喜欢，很有些相见恨晚的感觉。为什么呢？主要是惊诧于数据的强大力量。说到数据的价值，其实一堆一堆的数字、文字等等，是没什么价值的，价值在于数据中蕴含的信息。</p>

<p>机器学习和数据挖掘，就是这样的工具，可以把信息，从浩瀚的数据海洋中提取出来。海量数据的信息处理，就是最近很火的“大数据”了。在未来，互联网向各个传统行业，我们生活的方方面面不断渗透的过程中，数据挖掘和机器学习的方法，是可以做很多很多的事情的。</p>

<p>再说数据可视化，以前的时候理解一直很不到位，一直觉得数据可视化，就是用一种很好的方式，来展现信息，表达观点，这样可以提高沟通的效率，也很符合人的认知习惯。那么数据可视化，应该技术含量很低，更多的是个经验学科，自己领域里的数据，一般用什么样的形态来表示，这个从业时间长了，自己就了解了。这两天在看《Interative Data Visualization for the Web》这本书（中文好像叫《D3js实战》么？），只看了一点，就有很大收获。但从对数据可视化的由来和认识来讲，感觉作者理解的好深刻。数据可视化分为解释性的可视化（explainatory）和探索性的可视化（exploratory）。前者就是我一直认为的那样，而后者我导师一般说是“可视分析”，通过提供对数据的交互手段，帮助人们挖掘知识、信息。</p>

<p>那么数据可视化和数据挖掘机器学习应当是有着非常密切的关系的。先说解释性的可视化。一般来讲，我们说数据挖掘机器学习是非常强大的工具，可以帮助我们从数据中学习，以进行分类、回归、聚类等工作，解决实际问题。那么挖掘出来的信息，需要交流和传递，才能有产生价值，这时候，数据可视化可以帮助你，更好地把你想表达的信息传递出去。那么可视分析呢，意义在于，有些问题，数据挖掘可能帮不上忙，但是人们的长期工作以来，经验积累，有很多先验知识，这些知识一般比较难在数据挖掘的过程中有所帮助。那么可视分析就可以帮助这些有经验的人士，更好的操作数据，可以快速的产生数据的不同视图，让其他行业的专家也可以享受到挖掘的福利。这方面，美国已经有企业做的很成熟了，公司也都上市了，Tableau。回头我也要试用学习一下。</p>
]]></content>
  </entry>
  
</feed>
