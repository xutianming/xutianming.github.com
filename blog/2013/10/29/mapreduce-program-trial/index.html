
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>MapReduce初试 - Xutianming Blog</title>
  <meta name="author" content="Xutianming">

  
  <meta name="description" content="最近在尝试做一个行业关键词分类的项目，训练数据百万级，测试数据千万。数据量不大，但是我的机器跑来已经相当吃力了，于是想用一些简单的Hadoop知识，体验一下这个目前业内最流行的分布式计算框架。 以前接触过很多分布式计算的知识，也学习过MapReduce。甚至实习期间， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://xutianming.github.io/blog/2013/10/29/mapreduce-program-trial">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Xutianming Blog" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Xutianming Blog</a></h1>
  
    <h2>www.cnblogs.com/iteagle</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:xutianming.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">MapReduce初试</h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-10-29T20:46:00+08:00" pubdate data-updated="true">Oct 29<span>th</span>, 2013</time>
        
         | <a href="#disqus_thread">Comments</a>
        
      </p>
    
  </header>


<div class="entry-content"><p>最近在尝试做一个行业关键词分类的项目，训练数据百万级，测试数据千万。数据量不大，但是我的机器跑来已经相当吃力了，于是想用一些简单的Hadoop知识，体验一下这个目前业内最流行的分布式计算框架。</p>

<p>以前接触过很多分布式计算的知识，也学习过MapReduce。甚至实习期间，还多少使用到了hadoop的hive。但是一直都流于表面和概念，没有机会实践，甚至都不知道一个MapReduce程序如何来写，这次终于有机会尝试。</p>

<p>体验的过程并不顺利，为了简单起见，我使用Python和Streaming。参考网上的博客，很快就写出了MapReduce程序。这里的心得是，编写MapReduce程序并不比普通的编程难，关键是把算法分布式化，思考清楚，在Map和Reduce的过程中的数据流。这里分别附上我写的简单的Map，Reduce程序，作为以后工作的模板。</p>

<p>Mapper.py</p>

<pre><code>#!/usr/bin/env python
import math
import sys

features = []

fin = open("feature.txt","r")
for line in fin:
    winfo = line.split("\t")
    word = winfo[0].strip()
    features.append(word)
fin.close()


for line in sys.stdin :
    document = []
    info = line.strip().split("\t")
    for i in range(2,len(info)):
        document.append(info[i].strip())
    for feature in features:
        if feature in document :
            print '%s\t%s' % (feature, 1)
</code></pre>

<p>Reducer.py</p>

<pre><code>#!/usr/bin/env python
import math
import sys

current_word = None
current_count = 0
word = None

for line in sys.stdin:
    line = line.strip()
    word,count = line.split('\t')

try:
    count = int(count)
except ValueError:
    continue

if current_word == word:
    current_count += count
else :
    if current_word :
        print '%s\t%s' % (current_word,current_count)
    current_count = count
    current_word = word

if current_word == word:
    print '%s\t%s' % (current_word, current_count)
</code></pre>

<p>这一个统计DocumentFrequence的MapReduce程序。下面就一一描述下在编写这个程序中遇到的问题和解决方案。</p>

<ol>
<li>首先注意到Mapper中需要读入一个文件。一开始不懂文件应该怎么才可以被程序读到。尝试过放在HDFS和改变各种文件路径。其实只要在执行hadoop任务的时候，用<code>-file</code>参数指定就好了。</li>
<li>关于失败提示。<code># of failed Map Tasks exceeded allowed limit</code>,一开始的时候总是遇到。出现这个job失败提示的原因在于mapper程序有问题。执行失败，超过限度，job就会被杀死。所以mapper要做好本地测试。使用<code>cat input|python mapper.py|sort|reducer.py</code>可以对程序进行基本的测试。再就是在本地的hadoop平台上先跑一下，假如说没问题了，可以跑个5%，一般就可以提交到线上的集群了。</li>
<li>关于Streaming命令的各个参数。除了使用<code>-mapper</code>，<code>-reducer</code>之外。还可以利用<code>-D</code>选项，指定一些hadoop的运行参数，比如mapper和reducer的数量。这里有个比较重要的技巧。就是假如我们的执行逻辑中，只需要mapper不需要reducer。有几种办法，一个是不指定reducer，默认使用<code>IdentityReducer</code>，mapper的输入直接转化为reducer的输出；二是设置reducer数量为0，<code>-setReduceTasks=0</code>，有几个mapper即有几个输出文件。</li>
<li>最重要的一点，程序效率。上面给出的两个模板很高效。9GB的输入文件，十分钟即可在线上集群中完成。但是一开始并不是这样的。这个问题困扰了我整个周末。一开始，我想当然以为既然hadoop了，程序效率就不是短板了，我效率低，mapper分块小一点也很快完成，于是编程序的时候就很不在意效率。用list查找什么的，各种遍历循环，怎么好写怎么来。于是一开始我的程序测试好提交之后，job执行很慢，可以理解。令人崩溃的是，总是莫名其妙失败，我一度认为是线上集群不稳定弱爆了。后来在乐乐的提示下改进了程序的效率，list改用了hash，提高查找效率，去掉了几个循环。于是job很顺利也很迅速执行完了。事后分析，我觉得线上的集群可能做了很多的限制，我之前的写法，由于消耗太多的资源，由于本身优先级不高，就总是被delay，就会有莫名其妙的失败。所以mapreduce程序中，效率也是非常重要的，每一个task都高效执行，那么整个job都能很快完成，大大提高效率，节省时间啊！终于深刻认识到程序效率的重要性了。</li>
<li>最后一点，我还没有很好的解决。就是mapreduce程序的调试。hadoop实战这本书上有介绍debug的方法，我没怎么看懂，另外简单的程序，使用print大法打印一些调试信息和程序运行信息，很有利于快速定位bug。目前还不知道如何打印。如果在本地的hadoop的话，可以输出到<code>stderr</code>上，会最终输出到logs目录下的日志里。但是线上集群的话，就没有结点的访问权限，自然没法查看日志。所以我就想能否通过<code>Reporter</code>来打印一些消息。还没有尝试过，需要实践来验证。</li>
</ol>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">Xutianming</span></span>

      








  


<time datetime="2013-10-29T20:46:00+08:00" pubdate data-updated="true">Oct 29<span>th</span>, 2013</time>
      

<span class="categories">
  
    <a class='category' href='/blog/categories/ji-qi-xue-xi/'>机器学习</a>
  
</span>


    </p>
    
      <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://xutianming.github.io/blog/2013/10/29/mapreduce-program-trial/" data-via="" data-counturl="http://xutianming.github.io/blog/2013/10/29/mapreduce-program-trial/" >Tweet</a>
  
  
  
</div>

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2013/09/28/hadoop-first-trial/" title="Previous Post: Hadoop环境搭建小结">&laquo; Hadoop环境搭建小结</a>
      
      
        <a class="basic-alignment right" href="/blog/2013/11/14/text-classification-step-by-step/" title="Next Post: 行业关键词分类项目总结1">行业关键词分类项目总结1 &raquo;</a>
      
    </p>
  </footer>
</article>

  <section>
    <h1>Comments</h1>
    <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
  </section>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Categories</h1>
    <ul id="category-list"><li><a href='/blog/categories/codesegment/'>CodeSegment (1)</a></li><li><a href='/blog/categories/hadoop/'>Hadoop (1)</a></li><li><a href='/blog/categories/shu-ju-ke-shi-hua/'>数据可视化 (3)</a></li><li><a href='/blog/categories/wen-ben-wa-jue/'>文本挖掘 (4)</a></li><li><a href='/blog/categories/ji-qi-xue-xi/'>机器学习 (6)</a></li><li><a href='/blog/categories/za-xiang/'>杂项 (2)</a></li><li><a href='/blog/categories/sheng-huo/'>生活 (1)</a></li><li><a href='/blog/categories/suan-fa-ji-chu/'>算法基础 (4)</a></li><li><a href='/blog/categories/bian-cheng-yu-yan/'>编程语言 (1)</a></li></ul>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/11/14/text-classification-step-by-step/">行业关键词分类项目总结1</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/10/29/mapreduce-program-trial/">MapReduce初试</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/28/hadoop-first-trial/">Hadoop环境搭建小结</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/24/summary-of-wikivis-project-2/">知识可视化项目第一阶段总结2</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/09/23/summary-of-knowledge-visualization-project-stage-1/">知识可视化项目第一阶段小结</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/xutianming">@xutianming</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'xutianming',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>




<section>
  <h1>Tag Cloud</h1>
    <span id="tag-cloud"><a href='/blog/categories/codesegment' style='font-size: 110.0%'>CodeSegment(1)</a> <a href='/blog/categories/hadoop' style='font-size: 110.0%'>Hadoop(1)</a> <a href='/blog/categories/数据可视化' style='font-size: 130.0%'>数据可视化(3)</a> <a href='/blog/categories/文本挖掘' style='font-size: 140.0%'>文本挖掘(4)</a> <a href='/blog/categories/机器学习' style='font-size: 160.0%'>机器学习(6)</a> <a href='/blog/categories/杂项' style='font-size: 120.0%'>杂项(2)</a> <a href='/blog/categories/生活' style='font-size: 110.0%'>生活(1)</a> <a href='/blog/categories/算法基础' style='font-size: 140.0%'>算法基础(4)</a> <a href='/blog/categories/编程语言' style='font-size: 110.0%'>编程语言(1)</a> </span>
</section>

  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - Xutianming -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'xutianming';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://xutianming.github.io/blog/2013/10/29/mapreduce-program-trial/';
        var disqus_url = 'http://xutianming.github.io/blog/2013/10/29/mapreduce-program-trial/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
